{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from  keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_header(x, y, file='tain_data.h'):\n",
    "    '''\n",
    "    this method generate the\n",
    "    :param x:  input x data size\n",
    "    :param y:  input label (one hot label)\n",
    "    :return:\n",
    "    '''\n",
    "    # quantize input x\n",
    "    min_value = np.min(x)\n",
    "    max_value = np.max(x)\n",
    "\n",
    "    int_bits = int(np.ceil(np.log2(max(abs(min_value), abs(max_value)))))\n",
    "    dec_bits = 7 - int_bits\n",
    "    x = np.round(x*2**dec_bits).astype(np.int8)\n",
    "    \n",
    "#     print(x[0][0])\n",
    "    data = x.astype(dtype=\"byte\")\n",
    "    label = y\n",
    "    node = 0\n",
    "    with open(file, 'w') as f:\n",
    "        num_of_image = x.shape[0]\n",
    "        \n",
    "        print(\"Number of training images:\",num_of_image)\n",
    "        for i in range(num_of_image):\n",
    "            f.write('#define NODE_%d_TRAIN_IMG_%d {'%(node,i) )\n",
    "            (data[i]).flatten().tofile(f, sep=\", \") # convert 0~1 to 0~127\n",
    "            f.write('} \\n')\n",
    "            f.write('#define NODE_%d_TRAIN_IMG%d_LABEL'% (node, i))\n",
    "            f.write(' %d \\n \\n' % label[i])\n",
    "        f.write('#define NODE_%d_TOTAL_TRAIN_IMAGES %d \\n \\n'%(node,num_of_image))\n",
    "\n",
    "        f.write('static q7_t NODE_%d_TRAIN_IMAGES[%d][%d] = {' % (node,num_of_image, data[0].flatten().shape[0]))\n",
    "        f.write('NODE_%d_TRAIN_IMG_0'%(node))\n",
    "        for i in range(num_of_image -1):\n",
    "            f.write(',NODE_%d_TRAIN_IMG_%d'%(node, i+1))\n",
    "        f.write('};\\n\\n')\n",
    "\n",
    "        f.write('static q7_t NODE_%d_TRAIN_LABELS[%d] = {' % (node,num_of_image))\n",
    "        f.write('NODE_%d_TRAIN_IMG0_LABEL'%(node))\n",
    "        for i in range(num_of_image -1):\n",
    "            f.write(',NODE_%d_TRAIN_IMG%d_LABEL'%(node, i+1))\n",
    "        f.write('};\\n\\n')\n",
    "\n",
    "#     return 000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_bin(x, y, file='test_data.h'):\n",
    "    '''\n",
    "    method to generate the test data as a header file\n",
    "    :param x:  input x data size\n",
    "    :param y:  input label \n",
    "    :write to file \n",
    "    :return: nothing\n",
    "    '''\n",
    "    # quantize input x\n",
    "    min_value = np.min(x)\n",
    "    max_value = np.max(x)\n",
    "\n",
    "    int_bits = int(np.ceil(np.log2(max(abs(min_value), abs(max_value)))))\n",
    "    dec_bits = 7 - int_bits\n",
    "    x = np.round(x*2**dec_bits).astype(np.int8)\n",
    "    \n",
    "    data = x\n",
    "    label = y\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        num_of_image = x.shape[0]\n",
    "        print(\"Number of test images:\",num_of_image)\n",
    "        for i in range(num_of_image):\n",
    "            f.write('#define TEST_IMG%d {'% (i))\n",
    "            data[i].flatten().tofile(f, sep=\", \")\n",
    "            f.write('} \\n')\n",
    "            f.write('#define TEST_IMG%d_LABEL'% (i))\n",
    "            f.write(' %d \\n \\n' % label[i])\n",
    "        f.write('#define TOTAL_TEST_IMAGES %d \\n \\n'%(num_of_image))\n",
    "\n",
    "        f.write('static q7_t TEST_IMAGES[%d][%d] = {' % (num_of_image, data[0].flatten().shape[0]))\n",
    "        f.write('TEST_IMG0')\n",
    "        for i in range(num_of_image -1):\n",
    "            f.write(',TEST_IMG%d'%(i+1))\n",
    "        f.write('};\\n\\n')\n",
    "\n",
    "        f.write('static q7_t TEST_LABELS[%d] = {' % (num_of_image))\n",
    "        f.write('TEST_IMG0_LABEL')\n",
    "        for i in range(num_of_image -1):\n",
    "            f.write(',TEST_IMG%d_LABEL'%(i+1))\n",
    "        f.write('};\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 9 8 5]\n",
      "Number of training images: 400\n",
      "Number of test images: 4000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "mean = np.mean(x_train)\n",
    "stddev = np.std(x_train)\n",
    "\n",
    "x_train = (x_train - mean ) / stddev\n",
    "x_test =  (x_test-mean) /stddev\n",
    "\n",
    "\n",
    "# generate_train_header(x_train[:1500], y_train[:1500], file='cifar_train_data.h')\n",
    "# generate_test_bin(x_test[:1200], y_test[:1200], file='cifar_test_data.h')\n",
    "\n",
    "\n",
    "labelindices = np.random.choice(10, 4, replace=False)\n",
    "print(labelindices)\n",
    "\n",
    "subset_x_train = x_train[np.isin(y_train, labelindices).flatten()]\n",
    "subset_y_train = y_train[np.isin(y_train, labelindices).flatten()]\n",
    "# subset_y_train, _ = pd.factorize(np.concatenate( subset_y_train, axis=0 ))  \n",
    "\n",
    "subset_y_train = np.unique(subset_y_train, return_inverse=True)[1] \n",
    "\n",
    "\n",
    "subset_x_test = x_test[np.isin(y_test, labelindices).flatten()]\n",
    "subset_y_test = y_test[np.isin(y_test, labelindices).flatten()] \n",
    "generate_test_bin(subset_x_test, subset_y_test, file='cifar_test_cmsis.h')\n",
    "\n",
    "\n",
    "# subset_y_test, _ = pd.factorize(np.concatenate( subset_y_test, axis=0 ))  \n",
    "\n",
    "\n",
    "subset_y_test = np.unique(subset_y_test, return_inverse=True)[1] \n",
    "\n",
    "\n",
    "# subset_x_train = x_train[np.isin(y_train, [7,8,9]).flatten()] \n",
    "# subset_y_train = y_train[np.isin(y_train, [7,8,9]).flatten()]- 7\n",
    "\n",
    "# subset_x_test = x_test[np.isin(y_test, [7,8,9]).flatten()]\n",
    "# subset_y_test = y_test[np.isin(y_test, [7,8,9]).flatten()]- 7\n",
    "\n",
    "indices = np.random.choice(subset_x_train.shape[0], 400, replace=False)\n",
    "subset_x_train = subset_x_train[indices]\n",
    "subset_y_train= subset_y_train[indices]\n",
    "\n",
    "\n",
    "generate_train_header(subset_x_train, subset_y_train, file='cifar_train_data.h')\n",
    "generate_test_bin(subset_x_test, subset_y_test, file='cifar_test_data.h')\n",
    "\n",
    "\n",
    "# generate_train_header(x_train ,y_train, file='cifar_train_data.h')\n",
    "# generate_test_bin(x_test, y_test, file='cifar_test_data.h')\n",
    "\n",
    "\n",
    "# generate_train_header(subset_x_train, subset_y_train, file='cifar_train_data.h')\n",
    "# subset_x_train.shape[0]\n",
    "# federated_train_images(0, subset_x_train*127, subset_y_train, subset_x_train.shape[0], file='CIFAR3-TrainSet.h')\n",
    "\n",
    "# subset_x_test.shape[0]\n",
    "\n",
    "# imagesTestcfile(subset_x_test*127, subset_y_test,subset_x_test.shape[0] , file='CIFAR3-TestSet.h')\n",
    "\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_y_test = y_test[np.isin(y_test, labelindices).flatten()] \n",
    "# values = np.array([8,2,1,2,8])\n",
    "# a = np.concatenate( subset_y_test, axis=0 )\n",
    "# codes, uniques = pd.factorize(a)  # default: na_sentinel=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 3, 3, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3)\n",
      "(3000,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(subset_x_train.shape)\n",
    "print(subset_y_test.shape)\n",
    "print (np.unique(subset_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgplot = plt.imshow(subset_x_train[21])\n",
    "# print(subset_y_train[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
